---
description: Find best algorithms and optimize code using @mcp:context7, @mcp:fetch, @mcp:sequential-thinking, @mcp:memory with best practices
---

# /optimize - Algorithm & Code Optimization

## Purpose
Find optimal algorithms and best practices using comprehensive MCP research, then optimize code for performance, maintainability, and efficiency.

## Constitutional Authority
- **Article VII**: Autonomous Operations - Performance optimization
- **Article X**: Integration and Interoperability - Cross-project learning
- **Article IV**: Fundamental Principles - Code quality standards

## Workflow Sequence

### Phase 1: Performance Analysis (7-Schema Optimized)
```bash
# Identify optimization targets:
@mcp:filesystem → Scan codebase for:
- Performance bottlenecks
- Inefficient algorithms (O(n²) or worse)
- Memory leaks or excessive allocations
- Redundant computations
- Suboptimal data structures

# Analyze 7-schema performance metrics:
@mcp:math → Calculate:
- JSON parsing efficiency (target: 2.6x faster)
- Schema size compliance (≤10KB each)
- Attention budget utilization (59% optimization target)
- AegisKG pattern matching speed
- Memory-bank sync latency
- Context7 source prioritization accuracy
```

### Phase 2: MCP Research for Best Practices
```bash
# Comprehensive optimization research:

1. @mcp:context7 → Official documentation:
   - resolve-library-id for framework/language
   - get-library-docs for optimization patterns
   - Extract performance best practices
   - Find built-in optimization features

2. @mcp:fetch → Industry best practices:
   - Search algorithm optimization techniques
   - Find performance benchmarking studies
   - Retrieve community-proven patterns
   - Research latest optimization trends (2025)

3. @mcp:sequential-thinking → Complex analysis:
   - Break problem into optimization steps
   - Identify algorithmic improvements
   - Plan data structure changes
   - Design caching strategies

4. @mcp:memory → AegisKG pattern analysis:
   - Check local optimization successes via knowledge graph
   - Retrieve proven performance patterns
   - Analyze cross-project intelligence from @mcp:byterover-mcp
   - Extract 6-schema optimization strategies
   - Apply learned optimization techniques

5. @mcp:byterover-mcp → Cross-project intelligence:
   - Find similar optimization challenges across projects
   - Import successful 6-schema performance solutions
   - Share AegisKG optimization patterns globally
   - Validate Context7 source prioritization improvements
```

### Phase 3: Algorithm Selection
```bash
# Choose optimal algorithms:

Sorting:
- Small datasets (<50): Insertion Sort O(n²)
- Medium datasets: Quick Sort O(n log n)
- Large datasets: Merge Sort O(n log n) stable
- Nearly sorted: Tim Sort O(n) best case

Searching:
- Unsorted: Linear Search O(n)
- Sorted: Binary Search O(log n)
- Hash-based: Hash Table O(1) average
- Range queries: Binary Search Tree O(log n)

Data Structures:
- Fast access: HashMap/HashSet O(1)
- Ordered data: BTreeMap/BTreeSet O(log n)
- Queue operations: VecDeque O(1) both ends
- Priority queue: BinaryHeap O(log n)

String Operations:
- Pattern matching: KMP Algorithm O(n+m)
- Multiple patterns: Aho-Corasick O(n+m+z)
- Fuzzy matching: Levenshtein Distance O(nm)
```

### Phase 4: Optimization Implementation
```bash
# Apply optimizations:

1. Algorithm improvements:
   @mcp:filesystem → Replace inefficient algorithms
   - O(n²) → O(n log n) where possible
   - O(n) → O(1) with caching
   - Reduce nested loops
   - Use early returns

2. Data structure optimization:
   - Replace Vec with HashMap for lookups
   - Use BTreeMap for ordered iteration
   - Apply lazy evaluation patterns
   - Implement object pooling

3. Memory optimization:
   - Reduce allocations
   - Reuse buffers
   - Use stack over heap when possible
   - Implement copy-on-write patterns

4. Concurrency optimization:
   - Parallelize independent operations
   - Use async/await for I/O
   - Implement work-stealing schedulers
   - Apply lock-free data structures
```

### Phase 5: Benchmarking
```bash
# Measure improvements:

Before optimization:
@mcp:math → Record baseline metrics
- Execution time
- Memory usage
- CPU utilization
- Throughput

After optimization:
@mcp:math → Compare results
- Performance gain (%)
- Memory reduction (%)
- Efficiency improvement
- Scalability enhancement

# Language-specific benchmarking:
Rust: cargo bench
TypeScript: npm run benchmark
Python: pytest-benchmark
Go: go test -bench
Java: JMH benchmarks
```

### Phase 6: Code Quality Validation
```bash
# Ensure optimizations maintain quality:

1. EMD compliance:
   - Files still ≤80 lines
   - Deep nested structure preserved
   - Modular organization maintained

2. ZUV principle:
   - All variables used meaningfully
   - No premature optimization
   - Clear, maintainable code

3. Testing:
   - All tests still pass
   - Performance tests added
   - Edge cases covered
   - Regression tests included

4. Documentation:
   - Algorithm choices explained
   - Complexity analysis documented
   - Trade-offs noted
   - Benchmarks recorded
```

### Phase 7: Memory Bank Updates
```bash
# Document optimization patterns:

systemPatterns.json → Store:
- Successful optimization approaches
- Algorithm selection criteria
- Performance improvement metrics
- Best practices applied

techContext.json → Update:
- Performance characteristics
- Optimization decisions
- Benchmarking results
- MCP research findings

progress.json → Record:
- Performance improvements achieved
- Optimization milestones
- Efficiency gains

@mcp:memory → Store locally
@mcp:byterover-mcp → Sync to cloud
```

## Optimization Patterns
```bash
# Common optimization techniques:

1. Caching:
   - Memoization for expensive computations
   - LRU cache for frequent access
   - Lazy evaluation for deferred work

2. Batching:
   - Batch API calls
   - Bulk database operations
   - Grouped I/O operations

3. Indexing:
   - Database indexes for queries
   - Hash maps for fast lookups
   - Spatial indexes for geo data

4. Parallelization:
   - Multi-threading for CPU-bound
   - Async/await for I/O-bound
   - Work-stealing for load balancing

5. Compression:
   - Data compression for storage
   - Response compression for network
   - Stream compression for large data
```

## Performance Metrics
```bash
@mcp:math → Track improvements:

# Time Complexity:
Before: O(n²) → After: O(n log n)
Improvement: 100x faster for n=1000

# Space Complexity:
Before: O(n²) → After: O(n)
Memory savings: 99% for large datasets

# Real-world metrics:
- Response time: 500ms → 50ms (90% faster)
- Throughput: 100 req/s → 1000 req/s (10x)
- Memory usage: 1GB → 100MB (90% reduction)
- CPU utilization: 80% → 20% (75% reduction)
```

## Success Criteria
- ✅ Performance bottlenecks identified
- ✅ MCP research completed (all 5 MCPs)
- ✅ Optimal algorithms selected
- ✅ Optimizations implemented
- ✅ Benchmarks show improvement
- ✅ Code quality maintained (EMD/ZUV)
- ✅ Tests pass (100%)
- ✅ Documentation updated
- ✅ Patterns stored in memory bank

## Optimization Checklist
```bash
# Before optimization:
□ Profile code to find bottlenecks
□ Establish baseline metrics
□ Research best practices via MCPs
□ Plan optimization approach

# During optimization:
□ Apply algorithm improvements
□ Optimize data structures
□ Reduce memory allocations
□ Add parallelization where beneficial
□ Maintain code quality standards

# After optimization:
□ Run comprehensive benchmarks
□ Verify all tests pass
□ Document changes and trade-offs
□ Update memory bank with patterns
□ Store knowledge in @mcp:byterover-mcp
```

## Next Steps
After successful optimization:
1. Monitor performance in production
2. Continue profiling for new bottlenecks
3. Apply learned patterns to other code
4. Share optimization knowledge via @mcp:byterover-mcp
